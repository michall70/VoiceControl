import rclpy
import numpy as np
import math
import sys
import os
import threading
from rclpy.node import Node
from rclpy.qos import QoSProfile, QoSReliabilityPolicy, QoSHistoryPolicy, QoSDurabilityPolicy

from px4_msgs.msg import OffboardControlMode
from px4_msgs.msg import TrajectorySetpoint
from px4_msgs.msg import VehicleStatus

from dotenv import load_dotenv
import os
from langchain_community.chat_models import ChatTongyi
from langchain_core.tools import tool
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver

import speech_recognition as sr
import asyncio
import edge_tts
import pygame

# import queue
# import json
# import pyaudio
# from vosk import Model, KaldiRecognizer

Voice_Cmd = None #å£°éŸ³å‘½ä»¤èŠ‚ç‚¹
recognizer = sr.Recognizer()
microphone = sr.Microphone()

# import gemini_agent.agent_drone as agent_drone

class VoiceCmd(Node):

    def __init__(self):
        super().__init__('voice_cmd') #èŠ‚ç‚¹åç§°

                # QoS profiles
        qos_profile_pub = QoSProfile(
            reliability=QoSReliabilityPolicy.BEST_EFFORT,
            durability=QoSDurabilityPolicy.TRANSIENT_LOCAL,
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=1
        )

        qos_profile_sub = QoSProfile(
            reliability=QoSReliabilityPolicy.BEST_EFFORT,
            durability=QoSDurabilityPolicy.VOLATILE,
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=1
        )

        self.status_sub = self.create_subscription(     
            VehicleStatus,
            'fmu/out/vehicle_status',
            self.vehicle_status_callback,
            qos_profile_sub)
        self.status_sub = self.create_subscription(
            VehicleStatus,
            'fmu/out/vehicle_status_v1',
            self.vehicle_status_callback,
            qos_profile_sub)
        self.publisher_offboard_mode = self.create_publisher(
            OffboardControlMode, 
            'fmu/in/offboard_control_mode', 
            qos_profile_pub)
        self.publisher_trajectory = self.create_publisher(
            TrajectorySetpoint, 
            'fmu/in/trajectory_setpoint', 
            qos_profile_pub)
        timer_period = 0.1  # seconds
        self.timer = self.create_timer(timer_period, self.cmdloop_callback)
        self.trajectory_msg = TrajectorySetpoint()
        self.trajectory_msg.position[0] = 0
        self.trajectory_msg.position[1] = 0
        self.trajectory_msg.position[2] = -10        #é»˜è®¤é£è¡Œé«˜åº¦10ç±³

        self.nav_state = VehicleStatus.NAVIGATION_STATE_MAX
        self.arming_state = VehicleStatus.ARMING_STATE_DISARMED

    def vehicle_status_callback(self, msg):
        # TODO: handle NED->ENU transformation
        # print("NAV_STATUS: ", msg.nav_state)
        # print("  - offboard status: ", VehicleStatus.NAVIGATION_STATE_OFFBOARD)
        self.nav_state = msg.nav_state
        self.arming_state = msg.arming_state

    def cmdloop_callback(self):
        # Publish offboard control modes
        offboard_msg = OffboardControlMode()
        offboard_msg.timestamp = int(self.get_clock().now().nanoseconds / 1000)
        offboard_msg.position=True
        offboard_msg.velocity=False
        offboard_msg.acceleration=False
        self.publisher_offboard_mode.publish(offboard_msg)

        #å‘é€æ— äººæœºä½ç½®æŒ‡ä»¤
        if (self.nav_state == VehicleStatus.NAVIGATION_STATE_OFFBOARD and self.arming_state == VehicleStatus.ARMING_STATE_ARMED):
            self.publisher_trajectory.publish(self.trajectory_msg)

    def send_displacement(self, north, east, down): # å‘é€æ— äººæœºä½ç½®æŒ‡ä»¤NED ç›¸å¯¹åæ ‡
        self.trajectory_msg.position[0] += north
        self.trajectory_msg.position[1] += east
        self.trajectory_msg.position[2] += down
        self.publisher_trajectory.publish(self.trajectory_msg)

    def send_point(self, north, east, down): # å‘é€æ— äººæœºä½ç½®æŒ‡ä»¤NED ç»å¯¹åæ ‡
        self.trajectory_msg.position[0] = north
        self.trajectory_msg.position[1] = east
        self.trajectory_msg.position[2] = down
        self.publisher_trajectory.publish(self.trajectory_msg)

@tool
def drone_displacement(direction: str, distance: int) -> str:
    """
    æŒ‡å®šæ— äººæœºçš„é£è¡Œæ–¹å‘å’Œè·ç¦»ã€‚
    è‹¥æœ‰æŒ‡å®šåèˆªè§’åº¦ï¼Œè¯·å…ˆæ­£äº¤åˆ†è§£ä¸ºä¸œã€è¥¿ã€å—ã€åŒ—ã€ä¸Šã€ä¸‹å…­ä¸ªæ–¹å‘çš„åˆ†é‡ï¼Œå†è°ƒç”¨æ­¤å‡½æ•°ã€‚
    direction: ä¸œã€è¥¿ã€å—ã€åŒ—ã€ä¸Šã€ä¸‹ï¼Œè¯·é»˜è®¤è¾“å…¥åŒ—
    distance: é£è¡Œè·ç¦»ï¼Œå•ä½ç±³ï¼Œè¯·é»˜è®¤è¾“å…¥50ç±³
    è¿”å›æŒ‡ä»¤æ‰§è¡Œç»“æœå­—ç¬¦ä¸²
    """
    global Voice_Cmd
    if Voice_Cmd == None:
        return "âŒ é”™è¯¯ï¼šROS èŠ‚ç‚¹æœªå¯åŠ¨ã€‚"
    
    x, y, z = 0, 0, 0
    if direction == "ä¸œ":
        x = 1
    elif direction == "è¥¿":
        x = -1
    elif direction == "å—":
        y = -1
    elif direction == "åŒ—":
        y = 1
    elif direction == "ä¸Š":
        z = 1
    elif direction == "ä¸‹":
        z = -1
    else:
        return "âŒ é”™è¯¯ï¼šæœªçŸ¥æ–¹å‘ï¼"
    
    east = x * distance
    north = y * distance
    up = z * distance  # ROS ä¸­ä¸Šå‡æ˜¯è´Ÿå€¼ï¼Œä¸‹é™æ˜¯æ­£å€¼
    Voice_Cmd.send_displacement(north, east, -up)
    return f"âœ… å·²å‘é€æ— äººæœºé£è¡ŒæŒ‡ä»¤ï¼šæ–¹å‘ {direction}ï¼Œè·ç¦» {distance} ç±³ã€‚"

@tool
def drone_point(north: int, east: int, up: int) -> str:
    """
    æŒ‡å®šæ— äººæœºé£è¡Œåˆ°æŸä¸ªç»å¯¹ä½ç½®åæ ‡ï¼ˆ<åŒ—>,<ä¸œ>,<ä¸Š>)ã€‚
    north: åŒ—å‘åæ ‡ï¼Œå•ä½ç±³ï¼Œè¯·é»˜è®¤è¾“å…¥0
    east: ä¸œå‘åæ ‡ï¼Œå•ä½ç±³ï¼Œè¯·é»˜è®¤è¾“å…¥0
    up: ä¸Šå‘åæ ‡ï¼Œå•ä½ç±³ï¼Œè¯·é»˜è®¤è¾“å…¥10ï¼ˆé£è¡Œé«˜åº¦10ç±³ï¼‰
    è¿”å›æŒ‡ä»¤æ‰§è¡Œç»“æœå­—ç¬¦ä¸²
    """
    global Voice_Cmd
    if Voice_Cmd == None:
        return "âŒ é”™è¯¯ï¼šROS èŠ‚ç‚¹æœªå¯åŠ¨ã€‚"

    Voice_Cmd.send_point(north, east, -up)
    return f"âœ… å·²å‘é€æ— äººæœºé£è¡ŒæŒ‡ä»¤ï¼šåŒ— {north} ç±³ï¼Œä¸œ {east} ç±³ï¼Œä¸Š {up} ç±³ã€‚"

# å®šä¹‰â€œå˜´å·´â€å‡½æ•°ï¼šè®© AI è¯´è¯
async def text_to_speech(text):
    output_file = "response.mp3"
    # ä½¿ç”¨äº‘å¸Œçš„å£°éŸ³ï¼Œéå¸¸è‡ªç„¶
    communicate = edge_tts.Communicate(text, "zh-CN-YunxiNeural")
    await communicate.save(output_file)
    
    # æ’­æ”¾å£°éŸ³
    pygame.mixer.init()
    pygame.mixer.music.load(output_file)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        await asyncio.sleep(1)
    pygame.mixer.quit()
    os.remove(output_file) # æ’­æ”¾å®Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶

#loading
def get_dotenv_dir():
    """è·å– .env æ–‡ä»¶å¤¹è·¯å¾„"""
    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    if 'AGENT_DOTENV_DIR' in os.environ:
        return os.environ['AGENT_DOTENV_DIR']
agent_dotenv_dir = get_dotenv_dir()
load_dotenv(os.path.join(agent_dotenv_dir, ".env"))

llm = ChatTongyi(model="qwen-plus", temperature=0)
memory = MemorySaver()
tools = [drone_displacement, drone_point]
agent = create_agent(llm, tools, checkpointer = memory)
config = {"configurable": {"thread_id": "user_1"}}
result = {}

def SpeechRecognize():
    global result
    print("\nğŸ¤ è¯­éŸ³åŠ©æ‰‹æ­£åœ¨å¯åŠ¨ï¼ˆè¯´â€œé€€å‡ºâ€ä»¥é€€å‡º)")
    with sr.Microphone(device_index = None) as source:
        # è‡ªåŠ¨è°ƒèŠ‚ç¯å¢ƒå™ªéŸ³
        print("ğŸ¤ æ­£åœ¨è°ƒèŠ‚ç¯å¢ƒå™ªéŸ³ï¼Œè¯·ä¿æŒå®‰é™ 0.5 ç§’...")
        recognizer.adjust_for_ambient_noise(source, duration=0.8)
        
        try:
            print("ğŸ‘‚ æ­£åœ¨å€¾å¬...")
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=15)
            
            # 2. è¯­éŸ³è½¬æ–‡å­— (ä½¿ç”¨ Google å…è´¹æ¥å£ï¼Œéœ€è¦ä»£ç†)
            print("âŒ› æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
            user_text = recognizer.recognize_google(audio, language='zh-CN')
            print(f"ğŸ‘¤ ä½ è¯´: {user_text}")

            if "é€€å‡º" in user_text:
                print("ğŸ‘‹ å†è§ï¼")
                return
            
            # 3. å–‚ç»™ Agent
            print("ğŸ¤– Agent æ€è€ƒä¸­...")
            result = agent.invoke({"messages": [("human", user_text)]}, config)
            
            # 4. æ‰“å°å›å¤
            response = result["messages"][-1].content
            print(f"ğŸ¤– AI: {response}")
            # asyncio.run(text_to_speech(response))

        except sr.UnknownValueError:
            print("â“ æ²¡å¬æ¸…ï¼Œè¯·å†è¯´ä¸€éã€‚")
        except sr.RequestError as e:
            print(f"âŒ è¯­éŸ³æœåŠ¡å‡ºé”™ï¼ˆæ£€æŸ¥ä»£ç†ï¼‰: {e}")
        except Exception as e:
            print(f"âš ï¸ å‘ç”Ÿé”™è¯¯: {e}")

# rosçº¿ç¨‹å‡½æ•°
def start_ros_thread():
    rclpy.init()
    global Voice_Cmd
    Voice_Cmd = VoiceCmd()
    rclpy.spin(Voice_Cmd)

def main(args=None):
    # å¯åŠ¨ ROS çº¿ç¨‹
    ros_thread = threading.Thread(target=start_ros_thread, daemon=True)
    ros_thread.start()

    # å‘½ä»¤å¾ªç¯
    global result
    while True:
        user_input = input("ğŸ‘¨â€âœˆï¸ è¯·ä¸‹è¾¾é£è¡ŒæŒ‡ä»¤ ( sr è¯­éŸ³è¾“å…¥ï¼Œ q é€€å‡º): ")
        if user_input.lower() in ['q', 'quit', 'exit', 'é€€å‡º']:
            break
        if user_input.lower() in ['sr', 'speech', 'è¯­éŸ³']:
            SpeechRecognize()
        else:
            # è°ƒç”¨ Agent
            result = agent.invoke({"messages": [("human", user_input)]}, config)
            print(f"ğŸ¤– AI: {result['messages'][-1].content}")
            # asyncio.run(text_to_speech(result['messages'][-1].content))
    
    print("\n=== ğŸ•µï¸â€â™€ï¸ ä¾¦æ¢æ¨¡å¼ï¼šæŸ¥çœ‹ AI çš„å®Œæ•´æ€è€ƒè¿‡ç¨‹ ===")
    all_messages = result["messages"]

    for msg in all_messages:
        # msg.type å‘Šè¯‰ä½ æ˜¯è°è¯´çš„ (human, ai, tool)
        # msg.content æ˜¯å…·ä½“å†…å®¹
        print(f"\nã€è§’è‰²: {msg.type}ã€‘")
        print(f"å†…å®¹: {msg.content}")
        
        # å¦‚æœæ˜¯ AI æƒ³è¦è°ƒç”¨å·¥å…·ï¼Œæ‰“å°ä¸€ä¸‹å®ƒæƒ³è°ƒç”¨çš„ç»†èŠ‚ï¼ˆè¿›é˜¶æŸ¥çœ‹ï¼‰
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            print(f"   (åŠ¨ä½œ: AI å†³å®šè°ƒç”¨å·¥å…· -> {msg.tool_calls})")

    Voice_Cmd.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
